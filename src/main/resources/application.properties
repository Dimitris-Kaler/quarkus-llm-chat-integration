quarkus.http.port=8081
quarkus.swagger-ui.always-include=true
quarkus.smallrye-openapi.path=/openapi


#LLM CONFIG

ollama.base-url=http://localhost:11434
#ollama.model-name=deepseek-llm
ollama.temperature=0.7

#Memory Settings

conversation.max-messages=20  
conversation.timeout-minutes=30  


# RAG Configuration
rag.chunk.size=1000
rag.chunk.overlap=200
chat.use-rag=true

# Embedding Model
ollama.embedding-model=all-minilm